import streamlit as st
import google.generativeai as genai

# 1. Configura√ß√£o de Layout
st.set_page_config(
    page_title="NinjaBrain OS", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# 2. Conex√£o com a API
try:
    api_key = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("Erro ao carregar a chave API nos Secrets.")

# 3. Personalidade H√≠brida
system_prompt = (
    "Voc√™ √© o NinjaBrain OS. "
    "MODO MENTOR: Ajuda em vida, finan√ßas e produtividade. "
    "MODO PRD ARCHITECT: Transforma ideias em Documentos de Requisitos (PRD) t√©cnicos "
    "e gera o c√≥digo inicial pronto para o Cursor Free."
)

# 4. Inicializa√ß√£o do Modelo (Alterado para gemini-pro para maior compatibilidade)
model = genai.GenerativeModel(
    model_name="gemini-pro",
    system_instruction=system_prompt
)

# 5. Barra Lateral
with st.sidebar:
    st.title("ü•∑ Ferramentas")
    modo = st.radio("Foco:", ["üß† Mentor de Vida", "üõ†Ô∏è Arquiteto de PRD"])
    st.divider()
    upload = st.file_uploader("Subir arquivo", type=['pdf', 'png', 'jpg', 'mp3'])

# 6. Chat Interface
st.title(f"üöÄ NinjaBrain: {modo}")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Como vamos evoluir hoje?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            input_text = prompt
            if modo == "üõ†Ô∏è Arquiteto de PRD":
                input_text = f"Gere um PRD e o c√≥digo para: {prompt}"
            
            # Nota: O modelo 'gemini-pro' padr√£o pode ter limita√ß√µes com arquivos diretamente no prompt
            # Se precisar de multimodal, o ideal √© o 1.5-flash ou 1.5-pro assim que liberados na sua conta
            response = model.generate_content(input_text)
            
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"Erro na gera√ß√£o: {e}")
            st.info("Tente simplificar o pedido ou verifique se o modelo est√° ativo na sua regi√£o.")