import streamlit as st
import google.generativeai as genai

# 1. CONFIGURA√á√ÉO DE LAYOUT (Barra lateral sempre aberta)
st.set_page_config(
    page_title="NinjaBrain OS", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# 2. CONEX√ÉO BLINDADA (Configura√ß√£o da Chave)
if "GEMINI_API_KEY" not in st.secrets:
    st.error("‚ùå ERRO: Adicione a GEMINI_API_KEY nos Secrets do Streamlit Cloud.")
    st.stop()

# O segredo do 'transport' resolve o erro 404 v1beta
genai.configure(api_key=st.secrets["GEMINI_API_KEY"], transport='rest')

# 3. INICIALIZA√á√ÉO DO MODELO
# Usando o flash que √© o mais r√°pido e compat√≠vel
model = genai.GenerativeModel('gemini-1.5-flash')

# 4. BARRA LATERAL (Ferramentas e Exporta√ß√£o)
with st.sidebar:
    st.title("ü•∑ Ferramentas Ninja")
    st.success("üéØ Modo: Mentor de Vida")
    
    st.divider()
    st.subheader("üìÅ Central de Arquivos")
    arquivo = st.file_uploader("Analisar PDF, Imagem ou √Åudio", type=['pdf', 'png', 'jpg', 'jpeg', 'mp3', 'wav'])
    
    st.divider()
    st.subheader("üì• Exportar Mentoria")
    # Os bot√µes aparecer√£o aqui dinamicamente abaixo

# 5. INTERFACE DE CHAT
st.title("üöÄ NinjaBrain OS")

# Inicializa o hist√≥rico se n√£o existir
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe as mensagens do hist√≥rico
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# 6. L√ìGICA DE PROCESSAMENTO
if prompt := st.chat_input("Como posso te ajudar hoje, Kadson?"):
    # Salva pergunta do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        try:
            # Instru√ß√£o de personalidade embutida no prompt para evitar erro de sistema
            contexto = "Voc√™ √© o NinjaBrain, mentor de vida focado em produtividade. "
            full_prompt = f"{contexto} Pergunta do Kadson: {prompt}"
            
            # Chamada Multimodal ou Simples
            if arquivo:
                res = model.generate_content([full_prompt, arquivo])
            else: