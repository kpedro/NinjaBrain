import os
import google.generativeai as genai
from dotenv import load_dotenv

# 1. Localiza o arquivo .env na pasta raiz
base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
dotenv_path = os.path.join(base_dir, '.env')

# 2. Carrega as vari√°veis
load_dotenv(dotenv_path)

# Remove BOM de todas as vari√°veis de ambiente (corrige problema de encoding UTF-8 com BOM)
for key in list(os.environ.keys()):
    if key.startswith('\ufeff'):
        new_key = key.replace('\ufeff', '')
        os.environ[new_key] = os.environ[key]
        del os.environ[key]

chave = os.getenv("GEMINI_API_KEY")

if not chave:
    print("‚ùå Erro: Verifique sua chave no arquivo .env")
else:
    genai.configure(api_key=chave)
    
    # 2. Usa modelo dispon√≠vel (tenta 2.0-flash primeiro, fallback para pro)
    try:
        model = genai.GenerativeModel('models/gemini-2.0-flash')
    except:
        try:
            model = genai.GenerativeModel('models/gemini-pro')
        except:
            model = genai.GenerativeModel('gemini-pro')
    
    # 3. Personalidade do Agente
    contexto = """
    Voc√™ √© o NinjaBrain, assistente pessoal do Kadson para o CNU 2026.
    Sua miss√£o √© ser direto, t√©cnico e focado em aprova√ß√£o. 
    Sempre que poss√≠vel, use tabelas para organizar as informa√ß√µes.
    """

    print("--- ü•∑ NinjaBrain Online (Gemini 2.5) ---")
    
    while True:
        pergunta = input("\nKadson (ou 'sair'): ")
        if pergunta.lower() == 'sair':
            break
            
        print("Ninja pensando... üß†")
        
        try:
            # Enviamos o contexto de Ninja junto com a pergunta
            response = model.generate_content(f"{contexto}\n\nPergunta: {pergunta}")
            print(f"\nü§ñ NINJABRAIN:\n{response.text}")
        except Exception as e:
            print(f"‚ùå Erro na resposta: {e}")